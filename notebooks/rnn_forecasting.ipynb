{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0456ab26",
   "metadata": {},
   "source": [
    "# RNN Forecasting for IBM Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe98696d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea07c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(\"../src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c0cfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from rnn_forecasting import RNNForecaster\n",
    "from preprocessing import Preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d509a9",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70095ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\clemm\\Documents\\Personnal Projects\\ibm-stock-prices\\src\\preprocessing.py:73: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method='bfill').fillna(method='ffill')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>Adj Factor</th>\n",
       "      <th>Daily_Return</th>\n",
       "      <th>Cumulative_Return</th>\n",
       "      <th>SMA_30</th>\n",
       "      <th>SMA_100</th>\n",
       "      <th>EMA_30</th>\n",
       "      <th>EMA_100</th>\n",
       "      <th>Volatility_30d</th>\n",
       "      <th>BB_Mid</th>\n",
       "      <th>BB_Upper</th>\n",
       "      <th>BB_Lower</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-07-24</th>\n",
       "      <td>261.250000</td>\n",
       "      <td>262.049988</td>\n",
       "      <td>252.750000</td>\n",
       "      <td>260.510010</td>\n",
       "      <td>260.510010</td>\n",
       "      <td>22647700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.076238</td>\n",
       "      <td>268.722515</td>\n",
       "      <td>285.320334</td>\n",
       "      <td>259.747270</td>\n",
       "      <td>280.563528</td>\n",
       "      <td>263.605410</td>\n",
       "      <td>0.017962</td>\n",
       "      <td>285.837503</td>\n",
       "      <td>300.414279</td>\n",
       "      <td>271.260727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-25</th>\n",
       "      <td>260.019989</td>\n",
       "      <td>260.799988</td>\n",
       "      <td>256.350006</td>\n",
       "      <td>259.720001</td>\n",
       "      <td>259.720001</td>\n",
       "      <td>7758700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.003033</td>\n",
       "      <td>267.904569</td>\n",
       "      <td>284.593668</td>\n",
       "      <td>259.859437</td>\n",
       "      <td>279.218785</td>\n",
       "      <td>263.528472</td>\n",
       "      <td>0.017523</td>\n",
       "      <td>284.227003</td>\n",
       "      <td>302.594152</td>\n",
       "      <td>265.859855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-28</th>\n",
       "      <td>260.299988</td>\n",
       "      <td>264.000000</td>\n",
       "      <td>259.609985</td>\n",
       "      <td>263.209991</td>\n",
       "      <td>263.209991</td>\n",
       "      <td>5192500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.013438</td>\n",
       "      <td>271.517977</td>\n",
       "      <td>283.999667</td>\n",
       "      <td>259.976507</td>\n",
       "      <td>278.185959</td>\n",
       "      <td>263.522165</td>\n",
       "      <td>0.017764</td>\n",
       "      <td>282.902502</td>\n",
       "      <td>303.314561</td>\n",
       "      <td>262.490444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-29</th>\n",
       "      <td>264.299988</td>\n",
       "      <td>265.799988</td>\n",
       "      <td>261.019989</td>\n",
       "      <td>262.410004</td>\n",
       "      <td>262.410004</td>\n",
       "      <td>4627300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.003039</td>\n",
       "      <td>270.689699</td>\n",
       "      <td>283.506001</td>\n",
       "      <td>260.104052</td>\n",
       "      <td>277.168156</td>\n",
       "      <td>263.500142</td>\n",
       "      <td>0.017632</td>\n",
       "      <td>281.284003</td>\n",
       "      <td>302.832354</td>\n",
       "      <td>259.735651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-30</th>\n",
       "      <td>261.600006</td>\n",
       "      <td>262.000000</td>\n",
       "      <td>258.899994</td>\n",
       "      <td>260.260010</td>\n",
       "      <td>260.260010</td>\n",
       "      <td>3718300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.008193</td>\n",
       "      <td>268.463674</td>\n",
       "      <td>282.787002</td>\n",
       "      <td>260.236517</td>\n",
       "      <td>276.077308</td>\n",
       "      <td>263.435981</td>\n",
       "      <td>0.017323</td>\n",
       "      <td>279.737003</td>\n",
       "      <td>302.684959</td>\n",
       "      <td>256.789047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2025-07-24  261.250000  262.049988  252.750000  260.510010  260.510010   \n",
       "2025-07-25  260.019989  260.799988  256.350006  259.720001  259.720001   \n",
       "2025-07-28  260.299988  264.000000  259.609985  263.209991  263.209991   \n",
       "2025-07-29  264.299988  265.799988  261.019989  262.410004  262.410004   \n",
       "2025-07-30  261.600006  262.000000  258.899994  260.260010  260.260010   \n",
       "\n",
       "              Volume  Dividends  Stock Splits  Adj Factor  Daily_Return  \\\n",
       "Date                                                                      \n",
       "2025-07-24  22647700        0.0           0.0         1.0     -0.076238   \n",
       "2025-07-25   7758700        0.0           0.0         1.0     -0.003033   \n",
       "2025-07-28   5192500        0.0           0.0         1.0      0.013438   \n",
       "2025-07-29   4627300        0.0           0.0         1.0     -0.003039   \n",
       "2025-07-30   3718300        0.0           0.0         1.0     -0.008193   \n",
       "\n",
       "            Cumulative_Return      SMA_30     SMA_100      EMA_30     EMA_100  \\\n",
       "Date                                                                            \n",
       "2025-07-24         268.722515  285.320334  259.747270  280.563528  263.605410   \n",
       "2025-07-25         267.904569  284.593668  259.859437  279.218785  263.528472   \n",
       "2025-07-28         271.517977  283.999667  259.976507  278.185959  263.522165   \n",
       "2025-07-29         270.689699  283.506001  260.104052  277.168156  263.500142   \n",
       "2025-07-30         268.463674  282.787002  260.236517  276.077308  263.435981   \n",
       "\n",
       "            Volatility_30d      BB_Mid    BB_Upper    BB_Lower  \n",
       "Date                                                            \n",
       "2025-07-24        0.017962  285.837503  300.414279  271.260727  \n",
       "2025-07-25        0.017523  284.227003  302.594152  265.859855  \n",
       "2025-07-28        0.017764  282.902502  303.314561  262.490444  \n",
       "2025-07-29        0.017632  281.284003  302.832354  259.735651  \n",
       "2025-07-30        0.017323  279.737003  302.684959  256.789047  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor = Preprocessor(\"../data/raw/IBM_Stock_1980_2025.csv\")\n",
    "\n",
    "df = preprocessor.load_data()\n",
    "df = preprocessor.add_features()\n",
    "\n",
    "train, test = preprocessor.split(test_size=0.2)\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e78d250",
   "metadata": {},
   "source": [
    "## 2. LSTM Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7d9d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:   0%|          | 1/5456 [00:00<10:12,  8.90it/s, loss=0.00581]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 0] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 0] y_pred min/max: -0.0569/-0.0567\n",
      "[Batch 0] y_batch min/max: 0.0000/0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:   2%|▏         | 105/5456 [00:03<02:23, 37.24it/s, loss=0.0012] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 100] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 100] y_pred min/max: 0.0058/0.0059\n",
      "[Batch 100] y_batch min/max: 0.0000/0.2141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:   4%|▍         | 205/5456 [00:06<02:32, 34.35it/s, loss=0.000881]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 200] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 200] y_pred min/max: 0.0046/0.0047\n",
      "[Batch 200] y_batch min/max: 0.0000/0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:   6%|▌         | 305/5456 [00:09<02:33, 33.52it/s, loss=0.000807]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 300] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 300] y_pred min/max: 0.0067/0.0069\n",
      "[Batch 300] y_batch min/max: 0.0000/0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:   7%|▋         | 405/5456 [00:12<02:35, 32.43it/s, loss=0.000819]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 400] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 400] y_pred min/max: 0.0014/0.0016\n",
      "[Batch 400] y_batch min/max: 0.0000/0.2116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:   9%|▉         | 505/5456 [00:15<02:31, 32.78it/s, loss=0.000839]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 500] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 500] y_pred min/max: 0.0092/0.0098\n",
      "[Batch 500] y_batch min/max: 0.0000/0.1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  11%|█         | 605/5456 [00:18<02:14, 36.00it/s, loss=0.000826]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 600] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 600] y_pred min/max: 0.0034/0.0040\n",
      "[Batch 600] y_batch min/max: 0.0000/0.1641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  13%|█▎        | 705/5456 [00:21<02:10, 36.38it/s, loss=0.000806]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 700] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 700] y_pred min/max: 0.0024/0.0038\n",
      "[Batch 700] y_batch min/max: 0.0000/0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  15%|█▍        | 805/5456 [00:24<02:08, 36.19it/s, loss=0.000774]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 800] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 800] y_pred min/max: 0.0040/0.0048\n",
      "[Batch 800] y_batch min/max: 0.0000/0.0666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  17%|█▋        | 904/5456 [00:26<02:00, 37.85it/s, loss=0.000754]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 900] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 900] y_pred min/max: 0.0041/0.0050\n",
      "[Batch 900] y_batch min/max: 0.0000/0.1154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  18%|█▊        | 1006/5456 [00:29<02:09, 34.30it/s, loss=0.000745]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 1000] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 1000] y_pred min/max: 0.0038/0.0045\n",
      "[Batch 1000] y_batch min/max: 0.0000/0.0824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  20%|██        | 1106/5456 [00:32<02:10, 33.42it/s, loss=0.000726]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 1100] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 1100] y_pred min/max: 0.0037/0.0046\n",
      "[Batch 1100] y_batch min/max: 0.0000/0.1174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  22%|██▏       | 1205/5456 [00:36<02:07, 33.23it/s, loss=0.000748]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 1200] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 1200] y_pred min/max: 0.0067/0.0080\n",
      "[Batch 1200] y_batch min/max: 0.0000/0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  24%|██▍       | 1306/5456 [00:38<02:04, 33.32it/s, loss=0.000744]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 1300] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 1300] y_pred min/max: 0.0026/0.0059\n",
      "[Batch 1300] y_batch min/max: 0.0000/0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  26%|██▌       | 1403/5456 [00:41<02:02, 33.19it/s, loss=0.000737]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 1400] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 1400] y_pred min/max: 0.0036/0.0088\n",
      "[Batch 1400] y_batch min/max: 0.0000/0.1146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  28%|██▊       | 1503/5456 [00:44<01:52, 35.26it/s, loss=0.000724]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 1500] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 1500] y_pred min/max: 0.0052/0.0075\n",
      "[Batch 1500] y_batch min/max: 0.0000/0.1763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  29%|██▉       | 1603/5456 [00:47<01:49, 35.23it/s, loss=0.000712]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 1600] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 1600] y_pred min/max: 0.0039/0.0056\n",
      "[Batch 1600] y_batch min/max: 0.0000/0.0888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  31%|███       | 1703/5456 [00:50<02:03, 30.34it/s, loss=0.000708]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 1700] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 1700] y_pred min/max: 0.0045/0.0061\n",
      "[Batch 1700] y_batch min/max: 0.0000/0.1215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  33%|███▎      | 1803/5456 [00:53<01:55, 31.68it/s, loss=0.000704]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 1800] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 1800] y_pred min/max: 0.0045/0.0061\n",
      "[Batch 1800] y_batch min/max: 0.0000/0.1261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  35%|███▍      | 1903/5456 [00:56<01:52, 31.70it/s, loss=0.000704]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 1900] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 1900] y_pred min/max: 0.0009/0.0066\n",
      "[Batch 1900] y_batch min/max: 0.0000/0.1796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  37%|███▋      | 2003/5456 [01:00<01:43, 33.33it/s, loss=0.000708]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 2000] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 2000] y_pred min/max: 0.0057/0.0098\n",
      "[Batch 2000] y_batch min/max: 0.0000/0.0797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  39%|███▊      | 2103/5456 [01:03<01:38, 34.07it/s, loss=0.000708]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 2100] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 2100] y_pred min/max: 0.0038/0.0064\n",
      "[Batch 2100] y_batch min/max: 0.0000/0.1101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  40%|████      | 2203/5456 [01:05<01:29, 36.27it/s, loss=0.000715]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 2200] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 2200] y_pred min/max: 0.0045/0.0077\n",
      "[Batch 2200] y_batch min/max: 0.0000/0.1892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  42%|████▏     | 2304/5456 [01:08<01:28, 35.58it/s, loss=0.000713]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 2300] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 2300] y_pred min/max: 0.0013/0.0074\n",
      "[Batch 2300] y_batch min/max: 0.0000/0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  44%|████▍     | 2406/5456 [01:11<01:19, 38.13it/s, loss=0.00071] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 2400] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 2400] y_pred min/max: 0.0029/0.0078\n",
      "[Batch 2400] y_batch min/max: 0.0000/0.1001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  46%|████▌     | 2504/5456 [01:14<01:19, 37.00it/s, loss=0.000713]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 2500] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 2500] y_pred min/max: -0.0079/0.0040\n",
      "[Batch 2500] y_batch min/max: 0.0000/0.0167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  48%|████▊     | 2604/5456 [01:16<01:19, 35.67it/s, loss=0.000708]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 2600] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 2600] y_pred min/max: -0.0003/0.0094\n",
      "[Batch 2600] y_batch min/max: 0.0000/0.1124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  50%|████▉     | 2705/5456 [01:19<01:24, 32.46it/s, loss=0.000717]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 2700] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 2700] y_pred min/max: 0.0055/0.0101\n",
      "[Batch 2700] y_batch min/max: 0.0000/0.0886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  51%|█████▏    | 2805/5456 [01:22<01:12, 36.42it/s, loss=0.00071] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 2800] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 2800] y_pred min/max: 0.0019/0.0058\n",
      "[Batch 2800] y_batch min/max: 0.0000/0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  53%|█████▎    | 2906/5456 [01:25<01:08, 37.26it/s, loss=0.000709]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 2900] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 2900] y_pred min/max: 0.0055/0.0090\n",
      "[Batch 2900] y_batch min/max: 0.0000/0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  55%|█████▌    | 3007/5456 [01:28<01:03, 38.36it/s, loss=0.00071] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 3000] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 3000] y_pred min/max: -0.0027/0.0042\n",
      "[Batch 3000] y_batch min/max: 0.0000/0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  57%|█████▋    | 3104/5456 [01:31<01:02, 37.63it/s, loss=0.000709]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 3100] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 3100] y_pred min/max: 0.0016/0.0055\n",
      "[Batch 3100] y_batch min/max: 0.0000/0.0953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  59%|█████▊    | 3205/5456 [01:34<01:15, 29.87it/s, loss=0.00071] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 3200] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 3200] y_pred min/max: -0.0002/0.0098\n",
      "[Batch 3200] y_batch min/max: 0.0000/0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  61%|██████    | 3305/5456 [01:37<01:00, 35.81it/s, loss=0.000709]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 3300] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 3300] y_pred min/max: -0.0016/0.0090\n",
      "[Batch 3300] y_batch min/max: 0.0000/0.1865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  62%|██████▏   | 3405/5456 [01:40<00:56, 36.36it/s, loss=0.000707]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 3400] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 3400] y_pred min/max: -0.0051/0.0071\n",
      "[Batch 3400] y_batch min/max: 0.0000/0.1952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  64%|██████▍   | 3505/5456 [01:42<00:52, 36.84it/s, loss=0.000712]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 3500] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 3500] y_pred min/max: 0.0005/0.0090\n",
      "[Batch 3500] y_batch min/max: 0.0000/0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  66%|██████▌   | 3605/5456 [01:45<00:51, 36.13it/s, loss=0.00071] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 3600] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 3600] y_pred min/max: -0.0024/0.0070\n",
      "[Batch 3600] y_batch min/max: 0.0000/0.1121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  68%|██████▊   | 3706/5456 [01:48<00:47, 36.90it/s, loss=0.000707]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 3700] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 3700] y_pred min/max: -0.0071/0.0056\n",
      "[Batch 3700] y_batch min/max: 0.0000/0.1325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  70%|██████▉   | 3805/5456 [01:51<00:47, 35.11it/s, loss=0.000703]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 3800] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 3800] y_pred min/max: 0.0027/0.0118\n",
      "[Batch 3800] y_batch min/max: 0.0000/0.2089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  72%|███████▏  | 3903/5456 [01:54<00:50, 30.54it/s, loss=0.000699]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 3900] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 3900] y_pred min/max: -0.0074/0.0060\n",
      "[Batch 3900] y_batch min/max: 0.0000/0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  73%|███████▎  | 4002/5456 [01:58<00:57, 25.11it/s, loss=0.0007]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 4000] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 4000] y_pred min/max: -0.0062/0.0048\n",
      "[Batch 4000] y_batch min/max: 0.0000/0.1011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  75%|███████▌  | 4103/5456 [02:01<00:37, 35.63it/s, loss=0.000698]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 4100] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 4100] y_pred min/max: -0.0029/0.0081\n",
      "[Batch 4100] y_batch min/max: 0.0000/0.1027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  77%|███████▋  | 4203/5456 [02:04<00:37, 33.77it/s, loss=0.000697]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 4200] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 4200] y_pred min/max: 0.0040/0.0102\n",
      "[Batch 4200] y_batch min/max: 0.0000/0.1261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  79%|███████▉  | 4301/5456 [02:06<00:29, 38.87it/s, loss=0.000697]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 4300] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 4300] y_pred min/max: -0.0025/0.0099\n",
      "[Batch 4300] y_batch min/max: 0.0000/0.0764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  81%|████████  | 4406/5456 [02:09<00:28, 37.00it/s, loss=0.000696]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 4400] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 4400] y_pred min/max: -0.0007/0.0090\n",
      "[Batch 4400] y_batch min/max: 0.0000/0.0493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  83%|████████▎ | 4503/5456 [02:12<00:26, 35.49it/s, loss=0.000701]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 4500] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 4500] y_pred min/max: -0.0019/0.0098\n",
      "[Batch 4500] y_batch min/max: 0.0000/0.0797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  84%|████████▍ | 4603/5456 [02:15<00:24, 35.43it/s, loss=0.000701]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 4600] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 4600] y_pred min/max: -0.0061/0.0098\n",
      "[Batch 4600] y_batch min/max: 0.0000/0.0418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  86%|████████▌ | 4703/5456 [02:18<00:20, 36.36it/s, loss=0.000701]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 4700] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 4700] y_pred min/max: -0.0029/0.0128\n",
      "[Batch 4700] y_batch min/max: 0.0000/0.2463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  88%|████████▊ | 4804/5456 [02:21<00:20, 31.17it/s, loss=0.0007]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 4800] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 4800] y_pred min/max: -0.0137/0.0100\n",
      "[Batch 4800] y_batch min/max: 0.0000/0.0735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  90%|████████▉ | 4904/5456 [02:24<00:19, 28.51it/s, loss=0.000697]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 4900] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 4900] y_pred min/max: -0.0123/0.0169\n",
      "[Batch 4900] y_batch min/max: 0.0000/0.1321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  92%|█████████▏| 5003/5456 [02:28<00:14, 30.71it/s, loss=0.000696]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 5000] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 5000] y_pred min/max: -0.0041/0.0245\n",
      "[Batch 5000] y_batch min/max: 0.0000/0.2417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  94%|█████████▎| 5103/5456 [02:31<00:10, 34.54it/s, loss=0.000695]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 5100] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 5100] y_pred min/max: -0.0230/0.0380\n",
      "[Batch 5100] y_batch min/max: 0.0000/0.2221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  95%|█████████▌| 5205/5456 [02:35<00:07, 34.19it/s, loss=0.000695]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 5200] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 5200] y_pred min/max: -0.0308/0.0533\n",
      "[Batch 5200] y_batch min/max: 0.0000/0.1422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  97%|█████████▋| 5305/5456 [02:37<00:04, 36.87it/s, loss=0.000694]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 5300] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 5300] y_pred min/max: -0.0117/0.0324\n",
      "[Batch 5300] y_batch min/max: 0.0000/0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  99%|█████████▉| 5405/5456 [02:40<00:01, 34.37it/s, loss=0.000691]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 5400] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 5400] y_pred min/max: -0.0115/0.0307\n",
      "[Batch 5400] y_batch min/max: 0.0000/0.0791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Avg Loss: 0.000689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50:   0%|          | 4/5456 [00:00<02:25, 37.50it/s, loss=0.000538]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 0] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 0] y_pred min/max: -0.0194/0.0324\n",
      "[Batch 0] y_batch min/max: 0.0000/0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50:   2%|▏         | 103/5456 [00:03<04:54, 18.17it/s, loss=0.000606]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 100] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 100] y_pred min/max: -0.0022/0.0296\n",
      "[Batch 100] y_batch min/max: 0.0000/0.3115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50:   4%|▎         | 202/5456 [00:08<04:26, 19.75it/s, loss=0.000561]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 200] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 200] y_pred min/max: -0.0072/0.0207\n",
      "[Batch 200] y_batch min/max: 0.0000/0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50:   6%|▌         | 304/5456 [00:14<04:25, 19.39it/s, loss=0.000527]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 300] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 300] y_pred min/max: 0.0018/0.0190\n",
      "[Batch 300] y_batch min/max: 0.0000/0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50:   7%|▋         | 403/5456 [02:50<04:56, 17.02it/s, loss=0.000501]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 400] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 400] y_pred min/max: -0.0144/0.0200\n",
      "[Batch 400] y_batch min/max: 0.0000/0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50:   9%|▉         | 502/5456 [02:55<03:39, 22.53it/s, loss=0.000515]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 500] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 500] y_pred min/max: -0.0106/0.0378\n",
      "[Batch 500] y_batch min/max: 0.0000/0.1047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50:  11%|█         | 604/5456 [02:59<03:49, 21.18it/s, loss=0.000526]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 600] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 600] y_pred min/max: -0.0182/0.0356\n",
      "[Batch 600] y_batch min/max: 0.0000/0.1012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50:  13%|█▎        | 705/5456 [03:03<02:47, 28.31it/s, loss=0.000529]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 700] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 700] y_pred min/max: -0.0125/0.0486\n",
      "[Batch 700] y_batch min/max: 0.0000/0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50:  15%|█▍        | 803/5456 [03:06<02:33, 30.23it/s, loss=0.000537]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 800] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 800] y_pred min/max: -0.0071/0.0230\n",
      "[Batch 800] y_batch min/max: 0.0000/0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50:  17%|█▋        | 903/5456 [03:10<02:38, 28.67it/s, loss=0.000554]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 900] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 900] y_pred min/max: 0.0005/0.0831\n",
      "[Batch 900] y_batch min/max: 0.0000/0.0790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50:  18%|█▊        | 1005/5456 [03:13<02:24, 30.82it/s, loss=0.000538]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 1000] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 1000] y_pred min/max: -0.0107/0.0132\n",
      "[Batch 1000] y_batch min/max: 0.0000/0.0731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50:  20%|██        | 1103/5456 [03:18<03:28, 20.83it/s, loss=0.000555]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 1100] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 1100] y_pred min/max: -0.0058/0.0301\n",
      "[Batch 1100] y_batch min/max: 0.0000/0.0803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50:  22%|██▏       | 1201/5456 [03:23<03:23, 20.87it/s, loss=0.000555]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 1200] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 1200] y_pred min/max: -0.0018/0.1552\n",
      "[Batch 1200] y_batch min/max: 0.0000/0.0583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50:  24%|██▍       | 1303/5456 [03:27<03:23, 20.44it/s, loss=0.000545]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 1300] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 1300] y_pred min/max: -0.0119/0.0331\n",
      "[Batch 1300] y_batch min/max: 0.0000/0.1026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50:  26%|██▌       | 1403/5456 [03:32<03:20, 20.16it/s, loss=0.000548]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 1400] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 1400] y_pred min/max: -0.0044/0.0185\n",
      "[Batch 1400] y_batch min/max: 0.0000/0.1231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50:  28%|██▊       | 1503/5456 [03:38<03:42, 17.76it/s, loss=0.00055] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 1500] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 1500] y_pred min/max: -0.0107/0.0356\n",
      "[Batch 1500] y_batch min/max: 0.0000/0.1568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50:  29%|██▉       | 1602/5456 [03:43<03:16, 19.62it/s, loss=0.00055] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 1600] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 1600] y_pred min/max: -0.0001/0.0901\n",
      "[Batch 1600] y_batch min/max: 0.0000/0.1952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50:  31%|███       | 1701/5456 [03:47<02:00, 31.17it/s, loss=0.000548]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 1700] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 1700] y_pred min/max: -0.0070/0.0386\n",
      "[Batch 1700] y_batch min/max: 0.0000/0.1814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50:  33%|███▎      | 1803/5456 [03:50<02:01, 30.10it/s, loss=0.000545]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 1800] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 1800] y_pred min/max: -0.0036/0.0659\n",
      "[Batch 1800] y_batch min/max: 0.0000/0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50:  35%|███▍      | 1905/5456 [03:53<01:44, 33.86it/s, loss=0.000545]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 1900] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 1900] y_pred min/max: -0.0100/0.0513\n",
      "[Batch 1900] y_batch min/max: 0.0000/0.1613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50:  37%|███▋      | 2006/5456 [03:57<01:48, 31.68it/s, loss=0.000545]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 2000] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 2000] y_pred min/max: 0.0037/0.0687\n",
      "[Batch 2000] y_batch min/max: 0.0000/0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50:  39%|███▊      | 2105/5456 [04:00<01:34, 35.39it/s, loss=0.000539]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 2100] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 2100] y_pred min/max: -0.0093/0.0491\n",
      "[Batch 2100] y_batch min/max: 0.0000/0.0808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50:  40%|████      | 2205/5456 [04:03<01:45, 30.77it/s, loss=0.00054] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 2200] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 2200] y_pred min/max: -0.0017/0.0239\n",
      "[Batch 2200] y_batch min/max: 0.0000/0.1102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50:  42%|████▏     | 2305/5456 [04:06<01:30, 34.70it/s, loss=0.000544]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 2300] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 2300] y_pred min/max: -0.0056/0.0148\n",
      "[Batch 2300] y_batch min/max: 0.0000/0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50:  44%|████▍     | 2405/5456 [04:09<01:39, 30.68it/s, loss=0.000542]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 2400] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 2400] y_pred min/max: -0.0008/0.0829\n",
      "[Batch 2400] y_batch min/max: 0.0000/0.0593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50:  46%|████▌     | 2504/5456 [04:13<02:05, 23.51it/s, loss=0.00054] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 2500] X_batch.shape: torch.Size([32, 20, 1]), y_batch.shape: torch.Size([32, 1])\n",
      "[Batch 2500] y_pred min/max: -0.0099/0.0265\n",
      "[Batch 2500] y_batch min/max: 0.0000/0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m lstm_forecaster \u001b[38;5;241m=\u001b[39m RNNForecaster(\n\u001b[0;32m      2\u001b[0m     model_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlstm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      8\u001b[0m lstm_forecaster\u001b[38;5;241m.\u001b[39mprepare_data(train, test)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mlstm_forecaster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0001\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m lstm_predictions \u001b[38;5;241m=\u001b[39m lstm_forecaster\u001b[38;5;241m.\u001b[39mpredict()\n\u001b[0;32m     12\u001b[0m metrics \u001b[38;5;241m=\u001b[39m lstm_forecaster\u001b[38;5;241m.\u001b[39mevaluate(test\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(lstm_predictions):], lstm_predictions)\n",
      "File \u001b[1;32mc:\\Users\\clemm\\Documents\\Personnal Projects\\ibm-stock-prices\\src\\rnn_forecasting.py:109\u001b[0m, in \u001b[0;36mRNNForecaster.train\u001b[1;34m(self, epochs, lr)\u001b[0m\n\u001b[0;32m    106\u001b[0m losses \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    107\u001b[0m loop \u001b[38;5;241m=\u001b[39m tqdm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 109\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (X_batch, y_batch) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loop):\n\u001b[0;32m    110\u001b[0m     X_batch \u001b[38;5;241m=\u001b[39m X_batch\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    111\u001b[0m     y_batch \u001b[38;5;241m=\u001b[39m y_batch\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\clemm\\miniconda3\\envs\\IBM-env\\lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\clemm\\miniconda3\\envs\\IBM-env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    714\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\clemm\\miniconda3\\envs\\IBM-env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\clemm\\miniconda3\\envs\\IBM-env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\clemm\\miniconda3\\envs\\IBM-env\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:398\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    338\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\clemm\\miniconda3\\envs\\IBM-env\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:211\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    208\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    212\u001b[0m         collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map)\n\u001b[0;32m    213\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[0;32m    214\u001b[0m     ]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\clemm\\miniconda3\\envs\\IBM-env\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:212\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    208\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m--> 212\u001b[0m         \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[0;32m    214\u001b[0m     ]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\clemm\\miniconda3\\envs\\IBM-env\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:155\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 155\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32mc:\\Users\\clemm\\miniconda3\\envs\\IBM-env\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:272\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    270\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    271\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 272\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lstm_forecaster = RNNForecaster(\n",
    "    model_type=\"lstm\",\n",
    "    hidden_size=64,\n",
    "    num_layers=2,\n",
    "    window_size=20,\n",
    "    batch_size=32\n",
    ")\n",
    "lstm_forecaster.prepare_data(train, test)\n",
    "lstm_forecaster.train(epochs=50, lr=0.0001)\n",
    "lstm_predictions = lstm_forecaster.predict()\n",
    "\n",
    "metrics = lstm_forecaster.evaluate(test.iloc[-len(lstm_predictions):], lstm_predictions)\n",
    "\n",
    "rmse = metrics[\"rmse\"]\n",
    "mae = metrics[\"mae\"]\n",
    "mape = metrics[\"mape\"]\n",
    "\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"MAPE: {mape:.2f}%\")\n",
    "\n",
    "\n",
    "lstm_forecaster.plot_forecast(test.iloc[-len(lstm_predictions):], lstm_predictions, title=\"LSTM Forecast vs Actual\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e2eb11",
   "metadata": {},
   "source": [
    "## 2. LightGBM Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47e23f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\clemm\\Documents\\Personnal Projects\\ibm-stock-prices\\src\\preprocessing.py:149: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\b\\abs_34s6o8i12c\\croot\\libtorch_1751464457133\\work\\torch\\csrc\\utils\\tensor_new.cpp:257.)\n",
      "  self.X = torch.tensor(self.X, dtype=torch.float32).unsqueeze(-1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "LSTM: Expected input to be 2D or 3D, got 4D instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m lgbm_forecaster \u001b[38;5;241m=\u001b[39m RNNForecaster(\n\u001b[0;32m      2\u001b[0m     model_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlstm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      8\u001b[0m lgbm_forecaster\u001b[38;5;241m.\u001b[39mprepare_data(train, test)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mlgbm_forecaster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m lstm_predictions \u001b[38;5;241m=\u001b[39m lgbm_forecaster\u001b[38;5;241m.\u001b[39mpredict()\n\u001b[0;32m     12\u001b[0m metrics \u001b[38;5;241m=\u001b[39m lgbm_forecaster\u001b[38;5;241m.\u001b[39mevaluate(test\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(lstm_predictions):], lstm_predictions)\n",
      "File \u001b[1;32mc:\\Users\\clemm\\Documents\\Personnal Projects\\ibm-stock-prices\\src\\rnn_forecasting.py:110\u001b[0m, in \u001b[0;36mRNNForecaster.train\u001b[1;34m(self, epochs, lr)\u001b[0m\n\u001b[0;32m    108\u001b[0m y_batch \u001b[38;5;241m=\u001b[39m y_batch\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    109\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 110\u001b[0m rnn_out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(rnn_out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])\n\u001b[0;32m    112\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(y_pred\u001b[38;5;241m.\u001b[39msqueeze(), y_batch)\n",
      "File \u001b[1;32mc:\\Users\\clemm\\miniconda3\\envs\\IBM-env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\clemm\\miniconda3\\envs\\IBM-env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\clemm\\miniconda3\\envs\\IBM-env\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1075\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m   1073\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1074\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m-> 1075\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1076\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLSTM: Expected input to be 2D or 3D, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mD instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1077\u001b[0m         )\n\u001b[0;32m   1078\u001b[0m     is_batched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[0;32m   1079\u001b[0m     batch_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: LSTM: Expected input to be 2D or 3D, got 4D instead"
     ]
    }
   ],
   "source": [
    "lgbm_forecaster = RNNForecaster(\n",
    "    model_type=\"lstm\",\n",
    "    hidden_size=64,\n",
    "    num_layers=2,\n",
    "    window_size=20,\n",
    "    batch_size=32\n",
    ")\n",
    "lgbm_forecaster.prepare_data(train, test)\n",
    "lgbm_forecaster.train(epochs=50, lr=0.001)\n",
    "lstm_predictions = lgbm_forecaster.predict()\n",
    "\n",
    "metrics = lgbm_forecaster.evaluate(test.iloc[-len(lstm_predictions):], lstm_predictions)\n",
    "\n",
    "rmse = metrics[\"rmse\"]\n",
    "mae = metrics[\"mae\"]\n",
    "mape = metrics[\"mape\"]\n",
    "\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"MAPE: {mape:.2f}%\")\n",
    "\n",
    "\n",
    "lgbm_forecaster.plot_forecast(test.iloc[-len(lstm_predictions):], lstm_predictions, title=\"LSTM Forecast vs Actual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8067ff79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IBM-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
